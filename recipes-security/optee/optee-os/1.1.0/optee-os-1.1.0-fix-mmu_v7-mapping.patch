commit 919f7f877c5df44292b10921f87ebd43534cd498
Author: etienne carriere <etienne.carriere@st.com>
Date:   Tue May 3 14:48:54 2016 +0200

    core/mmu v7: provision some level2 mmu tables

diff --git a/core/arch/arm/include/mm/core_mmu.h b/core/arch/arm/include/mm/core_mmu.h
index 955af3d..a508c3c 100644
--- a/core/arch/arm/include/mm/core_mmu.h
+++ b/core/arch/arm/include/mm/core_mmu.h
@@ -303,16 +303,6 @@ paddr_t core_mmu_get_main_ttb_pa(void);
 vaddr_t core_mmu_get_main_ttb_va(void);
 paddr_t core_mmu_get_ul1_ttb_pa(void);
 vaddr_t core_mmu_get_ul1_ttb_va(void);
-
-/*
- * core_mmu_alloc_l2() - allocates a number of L2 tables
- * @map: description of the area to allocate for
- *
- * Allocates a number of L2 to cover the virtual address range
- * decribed by @map.
- * @returns NULL on failure or a pointer to the L2 table(s)
- */
-void *core_mmu_alloc_l2(struct tee_mmap_region *mm);
 #endif
 
 void core_mmu_get_mem_by_type(unsigned int type, vaddr_t *s, vaddr_t *e);
diff --git a/core/arch/arm/mm/core_mmu_v7.c b/core/arch/arm/mm/core_mmu_v7.c
index 017eb01..2c035ea 100644
--- a/core/arch/arm/mm/core_mmu_v7.c
+++ b/core/arch/arm/mm/core_mmu_v7.c
@@ -136,6 +136,8 @@
 #define ATTR_IWBWA_OWBWA_PRRR		PRRR_IDX(ATTR_IWBWA_OWBWA_INDEX, 2, 1)
 #define ATTR_IWBWA_OWBWA_NMRR		NMRR_IDX(ATTR_IWBWA_OWBWA_INDEX, 1, 1)
 
+static uint32_t *core_mmu_alloc_l2(void);
+
 enum desc_type {
 	DESC_TYPE_PAGE_TABLE,
 	DESC_TYPE_SECTION,
@@ -555,7 +557,7 @@ bool core_mmu_user_mapping_is_active(void)
 
 static paddr_t map_page_memarea(struct tee_mmap_region *mm)
 {
-	uint32_t *l2 = core_mmu_alloc_l2(mm);
+	uint32_t *l2 = core_mmu_alloc_l2();
 	size_t pg_idx;
 	uint32_t attr;
 
@@ -573,7 +575,7 @@ static paddr_t map_page_memarea(struct tee_mmap_region *mm)
 	/* Fill in the entries */
 	while ((pg_idx * SMALL_PAGE_SIZE) <
 		(mm->size + (mm->pa & SECTION_MASK))) {
-		l2[pg_idx] = ((mm->pa & ~SMALL_PAGE_MASK) +
+		l2[pg_idx] = ((mm->pa & ~SECTION_MASK) +
 				pg_idx * SMALL_PAGE_SIZE) | attr;
 		pg_idx++;
 	}
@@ -732,11 +734,15 @@ enum core_mmu_fault core_mmu_get_fault_type(uint32_t fsr)
 
 #if defined(CFG_MMU_V7_TTB)
 
+#ifndef MAX_XLAT_TABLES
+#define MAX_XLAT_TABLES		1
+#endif
+
 /* Main MMU L1 table for teecore */
 static uint32_t main_mmu_l1_ttb[TEE_MMU_L1_NUM_ENTRIES]
 	__attribute__((section(".nozi.mmu.l1"),
 		       aligned(TEE_MMU_L1_ALIGNMENT)));
-static uint32_t main_mmu_l2_ttb[TEE_MMU_L2_NUM_ENTRIES]
+static uint32_t main_mmu_l2_ttb[MAX_XLAT_TABLES][TEE_MMU_L2_NUM_ENTRIES]
 	__attribute__((section(".nozi.mmu.l2"),
 		       aligned(TEE_MMU_L2_ALIGNMENT)));
 
@@ -745,6 +751,20 @@ static uint32_t main_mmu_ul1_ttb[CFG_NUM_THREADS][TEE_MMU_UL1_NUM_ENTRIES]
 	__attribute__((section(".nozi.mmu.ul1"),
 		      aligned(TEE_MMU_UL1_ALIGNMENT)));
 
+/* support for basic not-freeable L2 mmu table allocation */
+static unsigned next_xlat __data;
+
+static uint32_t *core_mmu_alloc_l2(void)
+{
+	uint32_t *tbl;
+
+	assert(next_xlat < MAX_XLAT_TABLES);
+
+	tbl = main_mmu_l2_ttb[next_xlat++];
+	memset(tbl, 0, TEE_MMU_L2_NUM_ENTRIES * sizeof(uint32_t));
+	return tbl;
+}
+
 paddr_t core_mmu_get_main_ttb_pa(void)
 {
 	/* Note that this depends on flat mapping of TEE Core */
@@ -772,32 +792,4 @@ vaddr_t core_mmu_get_ul1_ttb_va(void)
 {
 	return (vaddr_t)main_mmu_ul1_ttb[thread_get_id()];
 }
-
-void *core_mmu_alloc_l2(struct tee_mmap_region *mm)
-{
-	/* Can't have this in .bss since it's not initialized yet */
-	static size_t l2_offs __attribute__((section(".data")));
-	const size_t l2_va_size = TEE_MMU_L2_NUM_ENTRIES * SMALL_PAGE_SIZE;
-	size_t l2_va_space = ((sizeof(main_mmu_l2_ttb) - l2_offs) /
-			     TEE_MMU_L2_SIZE) * l2_va_size;
-
-	if (l2_offs)
-		return NULL;
-	if (mm->size > l2_va_space)
-		return NULL;
-	l2_offs += ROUNDUP(mm->size, l2_va_size) / l2_va_size;
-	return main_mmu_l2_ttb;
-}
-
-#else /* defined(CFG_MMU_V7_TTB) */
-
-__weak void *core_mmu_alloc_l2(struct tee_mmap_region *mm __unused)
-{
-	/*
-	 * This function should be redefined in platform specific part if
-	 * needed.
-	 */
-	return NULL;
-}
-
-#endif /* !defined(CFG_MMU_V7_TTB) */
+#endif
